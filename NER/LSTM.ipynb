{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from tensorflow.keras import Model,Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
    "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D,Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "import gc\n",
    "gc.collect(),gc.collect()\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NER dataset.csv',encoding='latin1')\n",
    "words = list(set(df['Word'].values))\n",
    "words.append('ENDPAD')\n",
    "num_words = len(words)\n",
    "tags = list(set(df['Tag'].values))\n",
    "num_tags = len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    def __init__(self,data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        agg_func = lambda s:[(w,p,t) for w,p,t in zip(s['Word'].values.tolist(),\n",
    "                                                     s['POS'].values.tolist(),\n",
    "                                                     s['Tag'].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i+1 for i,w in enumerate(words)}\n",
    "tag2idx = {t: i for i,t, in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "max_len = 50\n",
    "\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences = X, padding='post', value=num_words-1)\n",
    "\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences = y, padding='post', value=tag2idx[\"O\"])\n",
    "y = [to_categorical(i, num_classes=num_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 50, 50)            1758950   \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 50, 50)            0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 50, 200)           120800    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 50, 17)            3417      \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1883167 (7.18 MB)\n",
      "Trainable params: 1883167 (7.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_word = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=num_words, output_dim=max_len, input_length=max_len)(input_word)\n",
    "model = SpatialDropout1D(0.1)(model)\n",
    "model = Bidirectional(LSTM(units=100,return_sequences=True,recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(num_tags, activation='softmax'))(model)\n",
    "model = Model(input_word, out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 [==============================] - 58s 100ms/step - loss: 0.0645 - accuracy: 0.9937 - val_loss: 0.0108 - val_accuracy: 0.9960\n",
      "Epoch 2/5\n",
      "540/540 [==============================] - 57s 105ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0063 - val_accuracy: 0.9981\n",
      "Epoch 3/5\n",
      "540/540 [==============================] - 58s 107ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 4/5\n",
      "540/540 [==============================] - 59s 109ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9985\n",
      "Epoch 5/5\n",
      "540/540 [==============================] - 58s 108ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9985\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=2,verbose=0, mode='max', restore_best_weights = False)\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,np.array(y_train),\n",
    "    validation_split=0.2,\n",
    "    batch_size = 64,\n",
    "    epochs = 5,\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "301a17a29b57d3836b7901af1621afd6d2b1f2298b9c7949191147cf2fea93e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
